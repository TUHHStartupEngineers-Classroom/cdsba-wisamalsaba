{
  "hash": "e71287196f5fadba4eb6907179f6508d",
  "result": {
    "markdown": "---\ntitle: \"Instrumental Variables\"\nauthor: \"Wisam Alsaba\"\nformat: \n    html:\n      code-line-numbers: true\n      df-print: paged\n---\n\n----\n#### **Assignment 9**\n\n::: {.cell hash='09_iv_cache/html/unnamed-chunk-1_9cf888f15726627bc9c90c9254d44fe5'}\n\n```{.r .cell-code}\n# Loading required libraries\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#> ✔ dplyr     1.1.3     ✔ readr     2.1.4\n#> ✔ forcats   1.0.0     ✔ stringr   1.5.1\n#> ✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n#> ✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n#> ✔ purrr     1.0.2     \n#> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#> ✖ dplyr::filter() masks stats::filter()\n#> ✖ dplyr::lag()    masks stats::lag()\n#> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(dagitty)\nlibrary(ggdag)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> \n#> Attaching package: 'ggdag'\n#> \n#> The following object is masked from 'package:stats':\n#> \n#>     filter\n```\n:::\n\n```{.r .cell-code}\nlibrary(estimatr)\nlibrary(AER)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n#> Loading required package: car\n#> Loading required package: carData\n#> \n#> Attaching package: 'car'\n#> \n#> The following object is masked from 'package:dplyr':\n#> \n#>     recode\n#> \n#> The following object is masked from 'package:purrr':\n#> \n#>     some\n#> \n#> Loading required package: lmtest\n#> Loading required package: zoo\n#> \n#> Attaching package: 'zoo'\n#> \n#> The following objects are masked from 'package:base':\n#> \n#>     as.Date, as.Date.numeric\n#> \n#> Loading required package: sandwich\n#> Loading required package: survival\n```\n:::\n\n```{.r .cell-code}\n# Q1 - Defining and Visualizing the DAG\ndag_structure <- dagify(\n  spentTime ~ featureUsed,\n  spentTime ~ Unobserved,\n  featureUsed ~ Unobserved,\n  featureUsed ~ encourgement,\n  exposure = \"featureUsed\",\n  latent = \"Unobserved\",\n  outcome = \"spentTime\",\n  coords = list(x = c(Unobserved = 1, featureUsed = 0, spentTime = 2, encourgement = -1),\n                y = c(Unobserved = 1, featureUsed = 0, spentTime = 0, encourgement = 0)),\n  labels = c(\n    \"spentTime\" = \"Time Spent on the App\",\n    \"featureUsed\" = \"Usage of New Feature\",\n    \"encourgement\" = \"User Encouragement for Feature Use\",\n    \"Unobserved\" = \"Undisclosed Factors\"\n  )\n)\nggdag(dag_structure, text = FALSE, use_labels = \"label\")\n```\n\n::: {.cell-output-display}\n![](09_iv_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Data Loading and Exploration\ndata_frame <- readRDS('C:/Users/wisam/OneDrive/Desktop/Causal_Data_Science_Data/Data/rand_enc.rds')\nhead(data_frame)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"rand_enc\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"used_ftr\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"time_spent\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\",\"2\":\"1\",\"3\":\"30.51346\"},{\"1\":\"0\",\"2\":\"0\",\"3\":\"19.78372\"},{\"1\":\"1\",\"2\":\"1\",\"3\":\"28.59107\"},{\"1\":\"0\",\"2\":\"0\",\"3\":\"18.63635\"},{\"1\":\"0\",\"2\":\"0\",\"3\":\"14.55074\"},{\"1\":\"1\",\"2\":\"0\",\"3\":\"12.41954\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\n# Q2 - Calculating Naive Estimate\nnaive_est <- lm(time_spent ~ used_ftr, data = data_frame)\nsummary(naive_est)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> lm(formula = time_spent ~ used_ftr, data = data_frame)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -20.4950  -3.5393   0.0158   3.5961  20.5051 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) 18.86993    0.06955   271.3   <2e-16 ***\n#> used_ftr    10.82269    0.10888    99.4   <2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 5.351 on 9998 degrees of freedom\n#> Multiple R-squared:  0.497,\tAdjusted R-squared:  0.497 \n#> F-statistic:  9881 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n# Q3 - Assessing Correlation Matrix and Observations\ncorrelation_matrix <- cor(data_frame) %>% round(2)\n\ncat(\"  ## The naive estimate (10.82269) surpasses the IV robust estimate using rand_enc (9.738175), suggesting an upward bias in the naive estimate. It implies an overestimation of used_ftr's impact on time_spent.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>   ## The naive estimate (10.82269) surpasses the IV robust estimate using rand_enc (9.738175), suggesting an upward bias in the naive estimate. It implies an overestimation of used_ftr's impact on time_spent.\n```\n:::\n\n```{.r .cell-code}\ncat(\"## A strong correlation exists between used_ftr and time_spent.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> ## A strong correlation exists between used_ftr and time_spent.\n```\n:::\n\n```{.r .cell-code}\ncat(\"   ## Assuming rand_enc as an instrumental variable appears reasonable, as it displays a weak correlation with the outcome (time_spent) and a stronger correlation with the treatment (used_ftr).\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>    ## Assuming rand_enc as an instrumental variable appears reasonable, as it displays a weak correlation with the outcome (time_spent) and a stronger correlation with the treatment (used_ftr).\n```\n:::\n\n```{.r .cell-code}\ncat(\"## Though the correlation between the instrumental variable and the outcome isn't zero (potentially due to noise), it remains relatively low.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> ## Though the correlation between the instrumental variable and the outcome isn't zero (potentially due to noise), it remains relatively low.\n```\n:::\n\n```{.r .cell-code}\n# Q4 - Estimating with Instrumental Variables Using 2SLS with rand_enc and Robust Standard Errors\nmodel_iv_robust <- iv_robust(time_spent ~ used_ftr | rand_enc, data = data_frame)\nsummary(model_iv_robust)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> \n#> Call:\n#> iv_robust(formula = time_spent ~ used_ftr | rand_enc, data = data_frame)\n#> \n#> Standard error type:  HC2 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value  Pr(>|t|) CI Lower CI Upper   DF\n#> (Intercept)   19.312     0.2248   85.89 0.000e+00   18.872    19.75 9998\n#> used_ftr       9.738     0.5353   18.19 8.716e-73    8.689    10.79 9998\n#> \n#> Multiple R-squared:  0.4921 ,\tAdjusted R-squared:  0.492 \n#> F-statistic:   331 on 1 and 9998 DF,  p-value: < 2.2e-16\n```\n:::\n\n```{.r .cell-code}\n## Hansen J Test\nresiduals_iv <- residuals(model_iv_robust)\nfitted_values_iv <- fitted(model_iv_robust)\nhansen_test_stat <- sum(residuals_iv * fitted_values_iv)\np_value_hansen <- 1 - pchisq(hansen_test_stat, df = 1)\n\ncat(\"Hansen J Test Statistic:\", hansen_test_stat, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Hansen J Test Statistic: 0\n```\n:::\n\n```{.r .cell-code}\ncat(\"P-value:\", p_value_hansen, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> P-value: 1\n```\n:::\n\n```{.r .cell-code}\ncat(\"  ## A Hansen J test with a test statistic near 0 and a p-value close to 1 suggests that the instrument used in the model doesn't violate over-identifying restrictions. It indicates the validity of the instrument, implying no evidence of endogeneity or correlation with the error term.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>   ## A Hansen J test with a test statistic near 0 and a p-value close to 1 suggests that the instrument used in the model doesn't violate over-identifying restrictions. It indicates the validity of the instrument, implying no evidence of endogeneity or correlation with the error term.\n```\n:::\n\n```{.r .cell-code}\ncat(\"Naive Estimate:\", coef(naive_est)['used_ftr'], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Naive Estimate: 10.82269\n```\n:::\n\n```{.r .cell-code}\ncat(\"IV Robust Estimate (rand_enc):\", model_iv_robust$coefficients['used_ftr'], \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> IV Robust Estimate (rand_enc): 9.738175\n```\n:::\n\n```{.r .cell-code}\ncat(\"  ## Since the naive estimate (10.82269) exceeds the IV robust estimate using rand_enc (9.738175), the naive estimate probably overestimates the effect of used_ftr on time_spent.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>   ## Since the naive estimate (10.82269) exceeds the IV robust estimate using rand_enc (9.738175), the naive estimate probably overestimates the effect of used_ftr on time_spent.\n```\n:::\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}